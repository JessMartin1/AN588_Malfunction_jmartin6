---
title: "AN588 Homework 4 (Fall 2023)"
author: "Jess Martin"
date: '10/25/2023'
output: 
  prettydoc::html_pretty:
    theme: "architect"
    toc: yes 
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Question #1

**Write a simple R function, Z.prop.test(), that can perform one- or two-sample Z-tests for proportion data, using the following guidelines:**

* Your function should take the following arguments: p1 and n1 (no default) representing the estimated proportion and sample size (i.e., based on your sample data); p2 and n2 (both defaulting to NULL) that contain a second sample’s proportion and sample size data in the event of a two-sample test; p0 (no default) as the expected value for the population proportion; and alternative (default “two.sided”) and conf.level (default 0.95), to be used in the same way as in the function t.test().

* When conducting a two-sample test, it should be p1 that is tested as being smaller or larger than p2 when alternative=“less” or alternative=“greater”, the same as in the use of x and y in the function t.test().

* The function should perform a one-sample Z-test using p1, n1, and p0 if either p2 or n2 (or both) is NULL.

* The function should contain a check for the rules of thumb we have talked about (n∗p>5 and n∗(1−p)>5) to ensure the validity of assuming the normal distribution in both the one- and two-sample settings. If this is violated, the function should still complete but it should also print an appropriate warning message.

* The function should return a list containing the members Z (the test statistic), P (the appropriate p value), and CI (the two-sided CI with respect to “conf.level” around p1 in the case of a one-sample test and around p2-p1 in the case of a two-sample test). For all test alternatives (“two.sided”, “greater”, “less”), calculate symmetric CIs based on quantiles of the normal distribution rather than worrying about calculating single-limit confidence bounds.

```{R, Question #1}
Z.prop.test <- function(p0, p1, n1, p2 = NULL, n2 = NULL, alternative = "two.sided", conf.level = 0.95) 
{
  # One sample Z-test
 if (is.null(p2) | is.null(n2)) {
   z <- (p1 - p0)/sqrt(p0*(1 - p0) / n1) #one sample z test
   if (alternative == "greater") {p <- pnorm(z, lower.tail = FALSE)}
   if (alternative == "less") {p <- pnorm(z, lower.tail = TRUE)}
   if (alternative == "two.sided") {
          if (z > 0) {
            pval <- 2 * pnorm(z, lower.tail = FALSE)
          }
          if (z < 0) {
            pval <- 2 * pnorm(z, lower.tail = TRUE)
          }}
    if ((n1 * p0 < 5) | (n1 * (1 - p0) < 5 )) {
      warning("Check data, assumption of normal distribution violated!")
    }
    
    upper <- p1 - qnorm(1 - conf.level / 2) * sqrt(p1 * (1 - p1) / n1)
    lower <- p1 + qnorm(1 - conf.level / 2) * sqrt(p1 * (1 - p1) / n1)
    ci <- c(lower, upper)
    
    result <- list(Z = z, P = pval, CI = ci)
    return(result)
 }
  # Two sample Z-test
 else {
    pstar <- ((p1*n1) + (p2*n2))/(n1 + n2) 
    z <- (p2 - p1)/sqrt((pstar * (1 - pstar)) * (1/n1 + 1/n2))
    if (alternative == "greater") {
        pval <- pnorm(z, lower.tail = FALSE)
      }
      if (alternative == "less") {
        pval <- pnorm(z, lower.tail = TRUE)
      }
      if (alternative == "two.sided") {
          if (z > 0) {
            pval <- 2 * pnorm(z, lower.tail = FALSE)
          }
          if (z < 0) {
            pval <- 2 * pnorm(z, lower.tail = TRUE)
          }}
    if ((n1 * p1 > 5) | (n1 * (1 - p1) > 5) | (n2 * p2 > 5) | (n2 * (1 - p2) > 5)) {
      warning("Check data, assumption of normal distribution violated!")
    }
    
    se <- sqrt(pstar * (1-pstar) * (1/n1 + 1/n2))
    upper <- (p2-p1) + qnorm(1 - (1 - conf.level)/2) * se
    lower <- (p2-p1) + qnorm((1 - conf.level)/2) * se
    ci <- c(lower, upper)
    
    result <- list(Z = z, P = pval, CI = ci)
    return(result)
  }
}
```

# Question #2

**The dataset from Kamilar and Cooper has in it a large number of variables related to life history and body size. For this exercise, the end aim is to fit a simple linear regression model to predict longevity (MaxLongevity_m) measured in months from species’ brain size (Brain_Size_Species_Mean) measured in grams. Do the following for both longevity~brain size and log(longevity)~log(brain size):**

```{r, Question #2, message = FALSE, warning = FALSE}
# Load Relevant Packages
library(ggplot2)
library(curl)
```

```{R}
# Load Relevant Dataset
f <- curl("https://raw.githubusercontent.com/fuzzyatelin/fuzzyatelin.github.io/master/AN588_Fall23/KamilarAndCooperData.csv")
d <- read.csv(f, header = TRUE, sep = ",", stringsAsFactors = FALSE)
head(d)
```
## Longevity~Brain Size
```{R, Step 1}
d <- na.omit(d)
l <- d$MaxLongevity_m
b <- d$Brain_Size_Species_Mean
```
* Fit the regression model and, using {ggplot2}, produce a scatterplot with the fitted line superimposed upon the data. Append the the fitted model equation to your plot (HINT: use the function geom_text()).
```{R, Step 2}
beta1 <- cor(l, b) * sd(l)/sd(b)
beta1
```

```{R, Step 3}
beta0 <- mean(l) - beta1 * mean(b)
beta0
```

```{R, Step 4}
g <- ggplot(data = d, aes(x = b, y = l)) + 
  geom_point() + 
  geom_smooth(method = "lm") +
  labs(title = "Scatterplot with Fitted Line: Brain Size vs. Longevity", 
       x = "Brain Size (grams)", y = "Longevity (months)") +
  theme_minimal()

equation <- paste("Longevity = ", beta1, " + ","Brain size = ", beta0, " + ", sep = "")

g + geom_text(x = 340, y = 400, label = equation)
```

* Identify and interpret the point estimate of the slope (β1), as well as the outcome of the test associated with the hypotheses H0: β1 = 0; HA: β1 ≠ 0. Also, find a 90 percent CI for the slope (β1) parameter.

We reject the null hypothesis (HA: β1 ≠ 0) in favor of the alternative hypothesis. There is a strong association between brain size and longevity- as brain size increases, longevity increases too.
```{R, Step 5}
m <- lm(l ~ b, data = d)
m
ci <- confint(m, level = 0.90)  
ci
```
* Using your model, add lines for the 90 percent confidence and prediction interval bands on the plot and add a legend to differentiate between the lines.
```{R, Step 6}
ci <- predict(m, newdata = data.frame(b = d$b), interval = "confidence", level = 0.90)
head(ci)

pi <- predict(m, newdata = data.frame(b = d$b), interval = "prediction", level = 0.90)  
head(pi)
```

```{R, Step 7}
df <- data.frame(cbind(ci, l, b, pi))
head(df)
names(df) <- c("l", "b", "CIfit", "CIlwr", "CIupr", "PIfit", "PIlwr", "PIupr")
head(df)
```

```{R, Step 8}
g <- ggplot(data = df, aes(x = b, y = l)) + 
  geom_point() +
  geom_line(aes(x = b, y = CIfit, color = "Confidence"), linetype = "solid") +
  geom_line(aes(x = b, y = CIlwr, color = "Confidence"), linetype = "solid") +
  geom_line(aes(x = b, y = CIupr, color = "Confidence"), linetype = "solid") +
  geom_line(aes(x = b, y = PIfit, color = "Prediction"), linetype = "dashed") +
  geom_line(aes(x = b, y = PIlwr, color = "Prediction"), linetype = "dashed") +
  geom_line(aes(x = b, y = PIupr, color = "Prediction"), linetype = "dashed") +
  labs(title = "Scatterplot with Fitted Line and Intervals", 
       x = "Brain Size (grams)", y = "Longevity (months)") +
  scale_color_manual(name = "Legend", values = c("Confidence" = "springgreen", "Prediction" = "steelblue1"),
                     labels = c("Confidence", "Prediction")) +
  theme_minimal()
g
```

* Produce a point estimate and associated 90 percent PI for the longevity of a species whose brain weight is 800 gm. Do you trust the model to predict observations accurately for this value of the explanatory variable? Why or why not?

I do not trust the above model to predict observations accurately- the majority of data is on one end of the plot (less than 400gm). How could it be accurately be predicting longevity of a species with the brain size of 800gm?  
```{R, Step 9}
new_data <- data.frame(b = 800) 
new_prediction <- predict(m, newdata = new_data, interval = "prediction", level = 0.90)  
new_prediction
```
## Log(Longevity)~Log(Brain Size)
```{R, Step 10}
d <- na.omit(d)
l2 <- log(d$MaxLongevity_m) 
b2 <- log(d$Brain_Size_Species_Mean)  
```
* Fit the regression model and, using {ggplot2}, produce a scatterplot with the fitted line superimposed upon the data. Append the the fitted model equation to your plot (HINT: use the function geom_text()).
```{R, Step 11}
beta1 <- cor(l2, b2) * sd(l2)/sd(b2)
beta1
```

```{R, Step 12}
beta0 <- mean(l2) - beta1 * mean(b2)
beta0
```

```{R, Step 13}
g <- ggplot(data = d, aes(x = b2, y = l2)) + 
  geom_point() + 
  geom_smooth(method = "lm") +
  labs(title = "Scatterplot with Fitted Line: Log(Brain Size) vs. Log(Longevity)", 
       x = "Log(Brain Size)", y = "Log(Longevity)") +
  theme_minimal()

equation <- paste("Log(Longevity) = ", beta0, " + ", "Log(Brain size) = ", beta1, sep = "")

g + geom_text(x = 4.4, y = 5.6, label = equation)
```

* Identify and interpret the point estimate of the slope (β1), as well as the outcome of the test associated with the hypotheses H0: β1 = 0; HA: β1 ≠ 0. Also, find a 90 percent CI for the slope (β1) parameter.
```{R, Step 14}
m2 <- lm(l2 ~ b2, data = d)
m2
ci2 <- confint(m2, level = 0.90)  
ci2
```

```{R, Step 15}
ci2 <- predict(m2, newdata = data.frame(b2 = d$b2), interval = "confidence", level = 0.90)
head(ci2)

pi2 <- predict(m2, newdata = data.frame(b2 = d$b2), interval = "prediction", level = 0.90)  
head(pi2)
```

```{R,Step 16}
df2 <- data.frame(cbind(ci2, l2, b2, pi2))
head(df2)
names(df2) <- c("l2", "b2", "CIfit", "CIlwr", "CIupr", "PIfit", "PIlwr", "PIupr")
head(df2)
```

```{R, Step 17}
g2 <- ggplot(data = df2, aes(x = b2, y = l2)) + 
  geom_point() +
  geom_line(aes(x = b2, y = CIfit, color = "Confidence"), linetype = "solid") +
  geom_line(aes(x = b2, y = CIlwr, color = "Confidence"), linetype = "solid") +
  geom_line(aes(x = b2, y = CIupr, color = "Confidence"), linetype = "solid") +
  geom_line(aes(x = b2, y = PIfit, color = "Prediction"), linetype = "dashed") +
  geom_line(aes(x = b2, y = PIlwr, color = "Prediction"), linetype = "dashed") +
  geom_line(aes(x = b2, y = PIupr, color = "Prediction"), linetype = "dashed") +
  labs(title = "Scatterplot with Fitted Line and Intervals", 
       x = "Log of Brain Size (grams)", y = "Log of Longevity (months)") +
  scale_color_manual(name = "Legend", values = c("Confidence" = "springgreen", "Prediction" = "steelblue1"),
                     labels = c("Confidence", "Prediction")) +
  theme_minimal()

g2
```

* Produce a point estimate and associated 90 percent PI for the longevity of a species whose brain weight is 800 gm. Do you trust the model to predict observations accurately for this value of the explanatory variable? Why or why not?
```{R, Step 18}
new_data <- data.frame(b2 = 800) 
new_prediction <- predict(m2, newdata = new_data, interval = "prediction", level = 0.90)  
new_prediction
```
* Looking at your two models, which do you think is better? Why?

The log-transformation model is better- the predicted values are considerably closer to the actual values.

# Challenges: Homework #3

* Writing the R function was BRUTAL. I had to keep referencing Modules 10 & 11 and online documentation. I did not get the chance to input values and test this function- I will do that for the Final Homework Assignment.
* I struggled knitting my Rmd file because of step #7 (i.e., creating a data frame from the combined values of the variables: ci, l, b, and pi). I forgot to add the command: head(df) to my chunk, which displayed only the first few rows of my data frame.
* I am not sure if I did the legends correctly for the plots on Question #2. Let me know.
* In hindsight, I should have placed the steps for both the non-transformation and log-transformation models together- it would have made my Rmd file look much neater. 